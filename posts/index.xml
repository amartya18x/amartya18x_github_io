<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Amartya</title>
    <link>https://amartya18x.github.io/posts/</link>
    <description>Recent content in Posts on Amartya</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Your Name</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://amartya18x.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>NonConvexity of neural networks</title>
      <link>https://amartya18x.github.io/posts/nn_nonconvex/</link>
      <pubDate>Sat, 01 Oct 2016 03:52:46 +0530</pubDate>
      
      <guid>https://amartya18x.github.io/posts/nn_nonconvex/</guid>
      <description>I don&amp;rsquo;t remember where I heard this arguement but it was a pretty interesting one and I couldn&amp;rsquo;t remember the entire reasoning and so as I began to think about it, I figured some of it out and I believe it is pretty reasonable. We have all argued that neural networks are difficult to optimize because they are non-convex(or non-concave) for that matter. What we don&amp;rsquo;t talk about so much is why is it that they are non-convex.</description>
    </item>
    
    <item>
      <title>Strong Convexity and Strong Smoothness</title>
      <link>https://amartya18x.github.io/posts/strconvex/</link>
      <pubDate>Thu, 15 Sep 2016 23:49:40 +0530</pubDate>
      
      <guid>https://amartya18x.github.io/posts/strconvex/</guid>
      <description>I am going to , inspired by the course on optimization that I am doing this semester, talk a bit about strong convexity and strong smoothness and our very popular gradient descent works on them. So, before going right into the details let&amp;rsquo;s have a quick chat about convexity in general and we do have a few ways of going about it.
I will go about with talking about two definitions of convex functions, the first one being general more than the second.</description>
    </item>
    
    <item>
      <title>The Cemetery of the mind!</title>
      <link>https://amartya18x.github.io/posts/poems/</link>
      <pubDate>Wed, 03 Aug 2016 22:09:00 +0530</pubDate>
      
      <guid>https://amartya18x.github.io/posts/poems/</guid>
      <description>Potato  He had always been there.
In the dark and wet soil waited he,
For going out to the lighter place.
He did hear about it from his crawling friend.
But he couldn&amp;rsquo;t move and so he waited
Once in a while drenched when it rained
And sometimes dried to a pulp
But he survived though all this,
For his mother piped down whatever he needed.
One fine day, there was a tug</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://amartya18x.github.io/posts/about_me/</link>
      <pubDate>Mon, 02 May 2016 17:06:56 +0530</pubDate>
      
      <guid>https://amartya18x.github.io/posts/about_me/</guid>
      <description>I, Amartya Sanyal, have graduated from IIT Kanpur with a B.Tech in Computer Science and Engineering and am going to join The University of Oxford from Oxford, 2017. For this position. I am going to be funded by THe Alan Turing Institute during this endeavour of mine. I will be supervised by Prof. Varun Kanade and Prof. Phil Torr during the period.
During the summers, I will be interning in the Cortex group of twitter under the mentorship of Nicholas Koumchatzky, who heads the Twitter Cortex group.</description>
    </item>
    
  </channel>
</rss>